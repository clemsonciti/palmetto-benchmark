---------------------------------
Using NVIDIA_NGC runtime.
Thu Mar 2 10:14:22 EST 2023
---------------------------------
INFO:    underlay of /etc/localtime required more than 50 (94) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (470) bind mounts
Training with a single process on 1 GPUs.
Model resnet50d created, param count:25576264
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 1
Train: 0 [   0/2502 (  0%)]  Loss: 6.977 (6.98)  Time: 22.328s,   22.93/s  (22.328s,   22.93/s)  LR: 4.000e-01  Data: 4.305 (4.305)
Train: 0 [  50/2502 (  2%)]  Loss: 6.757 (6.93)  Time: 0.458s, 1117.96/s  (0.889s,  575.99/s)  LR: 4.000e-01  Data: 0.027 (0.112)
Train: 0 [ 100/2502 (  4%)]  Loss: 6.608 (6.78)  Time: 0.459s, 1114.62/s  (0.676s,  756.86/s)  LR: 4.000e-01  Data: 0.027 (0.071)
Train: 0 [ 150/2502 (  6%)]  Loss: 6.430 (6.69)  Time: 0.461s, 1110.08/s  (0.605s,  845.99/s)  LR: 4.000e-01  Data: 0.027 (0.056)
Train: 0 [ 200/2502 (  8%)]  Loss: 6.341 (6.62)  Time: 0.462s, 1107.41/s  (0.570s,  899.00/s)  LR: 4.000e-01  Data: 0.028 (0.049)
Train: 0 [ 250/2502 ( 10%)]  Loss: 6.324 (6.55)  Time: 0.463s, 1105.61/s  (0.548s,  933.93/s)  LR: 4.000e-01  Data: 0.028 (0.045)
Train: 0 [ 300/2502 ( 12%)]  Loss: 6.180 (6.49)  Time: 0.463s, 1104.96/s  (0.534s,  958.62/s)  LR: 4.000e-01  Data: 0.027 (0.042)
Train: 0 [ 350/2502 ( 14%)]  Loss: 6.019 (6.44)  Time: 0.466s, 1099.13/s  (0.524s,  976.97/s)  LR: 4.000e-01  Data: 0.029 (0.040)
Train: 0 [ 400/2502 ( 16%)]  Loss: 5.966 (6.38)  Time: 0.464s, 1104.44/s  (0.517s,  991.15/s)  LR: 4.000e-01  Data: 0.028 (0.039)
Train: 0 [ 450/2502 ( 18%)]  Loss: 5.901 (6.33)  Time: 0.464s, 1103.31/s  (0.511s, 1002.47/s)  LR: 4.000e-01  Data: 0.027 (0.037)
Train: 0 [ 500/2502 ( 20%)]  Loss: 5.775 (6.28)  Time: 0.463s, 1106.04/s  (0.506s, 1011.66/s)  LR: 4.000e-01  Data: 0.027 (0.036)
Train: 0 [ 550/2502 ( 22%)]  Loss: 5.703 (6.23)  Time: 0.465s, 1101.10/s  (0.502s, 1019.39/s)  LR: 4.000e-01  Data: 0.028 (0.036)
Train: 0 [ 600/2502 ( 24%)]  Loss: 5.587 (6.19)  Time: 0.463s, 1105.90/s  (0.499s, 1025.87/s)  LR: 4.000e-01  Data: 0.027 (0.035)
Train: 0 [ 650/2502 ( 26%)]  Loss: 5.506 (6.14)  Time: 0.464s, 1104.21/s  (0.496s, 1031.44/s)  LR: 4.000e-01  Data: 0.028 (0.034)
Train: 0 [ 700/2502 ( 28%)]  Loss: 5.451 (6.10)  Time: 0.463s, 1106.13/s  (0.494s, 1036.22/s)  LR: 4.000e-01  Data: 0.028 (0.034)
Train: 0 [ 750/2502 ( 30%)]  Loss: 5.379 (6.06)  Time: 0.464s, 1104.62/s  (0.492s, 1040.41/s)  LR: 4.000e-01  Data: 0.027 (0.033)
Train: 0 [ 800/2502 ( 32%)]  Loss: 5.278 (6.02)  Time: 0.467s, 1095.88/s  (0.490s, 1044.13/s)  LR: 4.000e-01  Data: 0.029 (0.033)
Train: 0 [ 850/2502 ( 34%)]  Loss: 5.285 (5.98)  Time: 0.463s, 1104.95/s  (0.489s, 1047.39/s)  LR: 4.000e-01  Data: 0.028 (0.033)
Train: 0 [ 900/2502 ( 36%)]  Loss: 5.206 (5.94)  Time: 0.464s, 1102.77/s  (0.487s, 1050.27/s)  LR: 4.000e-01  Data: 0.027 (0.032)
Train: 0 [ 950/2502 ( 38%)]  Loss: 5.356 (5.90)  Time: 0.467s, 1096.84/s  (0.486s, 1052.89/s)  LR: 4.000e-01  Data: 0.027 (0.032)
Train: 0 [1000/2502 ( 40%)]  Loss: 5.150 (5.87)  Time: 0.465s, 1101.49/s  (0.485s, 1055.27/s)  LR: 4.000e-01  Data: 0.028 (0.032)
Train: 0 [1050/2502 ( 42%)]  Loss: 4.960 (5.83)  Time: 0.464s, 1104.50/s  (0.484s, 1057.41/s)  LR: 4.000e-01  Data: 0.027 (0.032)
Train: 0 [1100/2502 ( 44%)]  Loss: 5.062 (5.80)  Time: 0.464s, 1102.76/s  (0.483s, 1059.39/s)  LR: 4.000e-01  Data: 0.027 (0.032)
Train: 0 [1150/2502 ( 46%)]  Loss: 5.036 (5.76)  Time: 0.461s, 1110.05/s  (0.482s, 1061.19/s)  LR: 4.000e-01  Data: 0.025 (0.031)
Train: 0 [1200/2502 ( 48%)]  Loss: 5.000 (5.73)  Time: 0.464s, 1102.74/s  (0.482s, 1062.84/s)  LR: 4.000e-01  Data: 0.027 (0.031)
Train: 0 [1250/2502 ( 50%)]  Loss: 4.922 (5.70)  Time: 0.464s, 1103.87/s  (0.481s, 1064.37/s)  LR: 4.000e-01  Data: 0.027 (0.031)
Train: 0 [1300/2502 ( 52%)]  Loss: 4.877 (5.67)  Time: 0.464s, 1103.53/s  (0.480s, 1065.77/s)  LR: 4.000e-01  Data: 0.028 (0.031)
Train: 0 [1350/2502 ( 54%)]  Loss: 4.787 (5.63)  Time: 0.464s, 1103.79/s  (0.480s, 1067.04/s)  LR: 4.000e-01  Data: 0.027 (0.031)
Train: 0 [1400/2502 ( 56%)]  Loss: 4.803 (5.60)  Time: 0.464s, 1103.00/s  (0.479s, 1068.22/s)  LR: 4.000e-01  Data: 0.027 (0.031)
Train: 0 [1450/2502 ( 58%)]  Loss: 4.668 (5.57)  Time: 0.462s, 1109.13/s  (0.479s, 1069.34/s)  LR: 4.000e-01  Data: 0.026 (0.031)
Train: 0 [1500/2502 ( 60%)]  Loss: 4.733 (5.55)  Time: 0.465s, 1102.05/s  (0.478s, 1070.40/s)  LR: 4.000e-01  Data: 0.028 (0.030)
Train: 0 [1550/2502 ( 62%)]  Loss: 4.864 (5.52)  Time: 0.465s, 1101.93/s  (0.478s, 1071.36/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [1600/2502 ( 64%)]  Loss: 4.805 (5.49)  Time: 0.464s, 1103.62/s  (0.477s, 1072.30/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [1650/2502 ( 66%)]  Loss: 4.596 (5.46)  Time: 0.463s, 1106.08/s  (0.477s, 1073.20/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [1700/2502 ( 68%)]  Loss: 4.442 (5.44)  Time: 0.463s, 1105.18/s  (0.477s, 1074.03/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [1750/2502 ( 70%)]  Loss: 4.599 (5.41)  Time: 0.461s, 1110.08/s  (0.476s, 1074.84/s)  LR: 4.000e-01  Data: 0.024 (0.030)
Train: 0 [1800/2502 ( 72%)]  Loss: 4.526 (5.39)  Time: 0.464s, 1102.73/s  (0.476s, 1075.58/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [1850/2502 ( 74%)]  Loss: 4.458 (5.36)  Time: 0.464s, 1103.62/s  (0.476s, 1076.28/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [1900/2502 ( 76%)]  Loss: 4.396 (5.34)  Time: 0.464s, 1102.76/s  (0.475s, 1076.97/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [1950/2502 ( 78%)]  Loss: 4.475 (5.32)  Time: 0.464s, 1104.16/s  (0.475s, 1077.63/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [2000/2502 ( 80%)]  Loss: 4.430 (5.29)  Time: 0.465s, 1101.98/s  (0.475s, 1078.24/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [2050/2502 ( 82%)]  Loss: 4.312 (5.27)  Time: 0.463s, 1105.59/s  (0.475s, 1078.80/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [2100/2502 ( 84%)]  Loss: 4.400 (5.25)  Time: 0.464s, 1103.25/s  (0.474s, 1079.36/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [2150/2502 ( 86%)]  Loss: 4.348 (5.23)  Time: 0.464s, 1103.04/s  (0.474s, 1079.89/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [2200/2502 ( 88%)]  Loss: 4.240 (5.20)  Time: 0.464s, 1104.45/s  (0.474s, 1080.39/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [2250/2502 ( 90%)]  Loss: 4.141 (5.18)  Time: 0.464s, 1103.37/s  (0.474s, 1080.86/s)  LR: 4.000e-01  Data: 0.027 (0.030)
Train: 0 [2300/2502 ( 92%)]  Loss: 4.126 (5.16)  Time: 0.464s, 1102.60/s  (0.474s, 1081.31/s)  LR: 4.000e-01  Data: 0.027 (0.029)
Train: 0 [2350/2502 ( 94%)]  Loss: 4.194 (5.14)  Time: 0.465s, 1101.45/s  (0.473s, 1081.73/s)  LR: 4.000e-01  Data: 0.028 (0.029)
Train: 0 [2400/2502 ( 96%)]  Loss: 4.180 (5.12)  Time: 0.465s, 1101.62/s  (0.473s, 1082.14/s)  LR: 4.000e-01  Data: 0.028 (0.029)
Train: 0 [2450/2502 ( 98%)]  Loss: 4.081 (5.10)  Time: 0.464s, 1104.18/s  (0.473s, 1082.53/s)  LR: 4.000e-01  Data: 0.027 (0.029)
Train: 0 [2500/2502 (100%)]  Loss: 4.160 (5.09)  Time: 0.462s, 1108.93/s  (0.473s, 1082.86/s)  LR: 4.000e-01  Data: 0.026 (0.029)
Train: 0 [2501/2502 (100%)]  Loss: 4.130 (5.09)  Time: 0.435s, 1176.97/s  (0.473s, 1082.90/s)  LR: 4.000e-01  Data: 0.000 (0.029)
Test: [   0/97]  Time: 4.848 (4.848)  Loss:  3.1387 (3.1387)  Acc@1: 32.4219 (32.4219)  Acc@5: 61.9141 (61.9141)
Test: [  50/97]  Time: 0.145 (0.351)  Loss:  4.4688 (3.8990)  Acc@1: 18.7500 (21.6682)  Acc@5: 34.7656 (44.5159)
Test: [  97/97]  Time: 1.345 (0.312)  Loss:  3.7227 (3.9186)  Acc@1: 27.3810 (22.0760)  Acc@5: 49.7024 (44.5460)
/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
Current checkpoints:
 ('./output/train/20230302-151453-resnet50d-224/checkpoint-0.pth.tar', 22.076000003051757)

*** Best metric: 22.076000003051757 (epoch 0)
Total runtime (s): 1248
 
 
+------------------------------------------+ 
| PALMETTO CLUSTER PBS RESOURCES REQUESTED | 
+------------------------------------------+ 
 
mem=372gb,walltime=02:00:00,ncpus=56
 
 
+-------------------------------------+ 
| PALMETTO CLUSTER PBS RESOURCES USED | 
+-------------------------------------+ 
 
cput=02:13:12,mem=167007312kb,walltime=00:20:55,ncpus=56,cpupercent=590,vmem=1129819648kb
 
 
